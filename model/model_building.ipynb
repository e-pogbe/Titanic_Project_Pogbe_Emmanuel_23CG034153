{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf93d55",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction System\n",
    "## Machine Learning Model Development\n",
    "\n",
    "This notebook develops a machine learning model to predict whether a passenger survived the Titanic disaster based on selected features.\n",
    "\n",
    "### Selected Features (5 input features):\n",
    "1. **Pclass** - Passenger class (1, 2, or 3)\n",
    "2. **Sex** - Gender (male or female)\n",
    "3. **Age** - Age in years\n",
    "4. **SibSp** - Number of siblings/spouses aboard\n",
    "5. **Fare** - Ticket fare\n",
    "\n",
    "### Target Variable:\n",
    "**Survived** (0 = Did not survive, 1 = Survived)\n",
    "\n",
    "### Algorithm Used:\n",
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f093bcc1",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d858b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49940a4b",
   "metadata": {},
   "source": [
    "## Step 2: Define the TitanicSurvivalPredictor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab58b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TitanicSurvivalPredictor class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class TitanicSurvivalPredictor:\n",
    "    \"\"\"\n",
    "    A machine learning model to predict Titanic passenger survival.\n",
    "    \n",
    "    Selected Features (5 input features):\n",
    "    1. Pclass - Passenger class (1, 2, or 3)\n",
    "    2. Sex - Gender (male or female)\n",
    "    3. Age - Age in years\n",
    "    4. SibSp - Number of siblings/spouses aboard\n",
    "    5. Fare - Ticket fare\n",
    "    \n",
    "    Target Variable: Survived (0 = Did not survive, 1 = Survived)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path='titanic_model.pkl'):\n",
    "        \"\"\"Initialize the predictor with model path.\"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.label_encoders = {}\n",
    "        self.feature_names = ['Pclass', 'Sex', 'Age', 'SibSp', 'Fare']\n",
    "        \n",
    "    def load_data(self, filepath):\n",
    "        \"\"\"\n",
    "        Load the Titanic dataset from CSV file.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to the CSV file\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame containing the loaded data\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 1: LOADING DATASET\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"Dataset loaded successfully!\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        print(f\"Columns: {list(df.columns)}\\n\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, df, is_training=True):\n",
    "        \"\"\"\n",
    "        Perform comprehensive data preprocessing.\n",
    "        \n",
    "        Includes:\n",
    "        - Feature selection\n",
    "        - Handling missing values\n",
    "        - Encoding categorical variables\n",
    "        - Feature scaling\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame to preprocess\n",
    "            is_training: Boolean indicating if this is training data\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed features (X) and target (y) if training,\n",
    "            or just features (X) if testing\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 2: DATA PREPROCESSING\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Feature selection: Select only required features\n",
    "        print(\"\\na) Feature Selection:\")\n",
    "        print(f\"   Selected features: {self.feature_names}\")\n",
    "        print(\"   Target variable: Survived\")\n",
    "        \n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        # Display missing values before handling\n",
    "        print(f\"\\n   Missing values before handling:\")\n",
    "        print(f\"   - Pclass: {df_processed['Pclass'].isna().sum()}\")\n",
    "        print(f\"   - Sex: {df_processed['Sex'].isna().sum()}\")\n",
    "        print(f\"   - Age: {df_processed['Age'].isna().sum()}\")\n",
    "        print(f\"   - SibSp: {df_processed['SibSp'].isna().sum()}\")\n",
    "        print(f\"   - Fare: {df_processed['Fare'].isna().sum()}\")\n",
    "        \n",
    "        # Handle missing values\n",
    "        print(f\"\\nb) Handling Missing Values:\")\n",
    "        \n",
    "        # Fill Age with median\n",
    "        age_median = df_processed['Age'].median()\n",
    "        df_processed['Age'].fillna(age_median, inplace=True)\n",
    "        print(f\"   - Age: Filled missing values with median ({age_median:.2f})\")\n",
    "        \n",
    "        # Fill Fare with median\n",
    "        fare_median = df_processed['Fare'].median()\n",
    "        df_processed['Fare'].fillna(fare_median, inplace=True)\n",
    "        print(f\"   - Fare: Filled missing values with median ({fare_median:.2f})\")\n",
    "        \n",
    "        # Drop rows with missing Embarked (if any) - but we're not using Embarked in our features\n",
    "        df_processed.dropna(subset=['Sex'], inplace=True)\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        print(f\"\\nc) Encoding Categorical Variables:\")\n",
    "        \n",
    "        # Sex encoding\n",
    "        if is_training:\n",
    "            self.label_encoders['Sex'] = LabelEncoder()\n",
    "            df_processed['Sex'] = self.label_encoders['Sex'].fit_transform(df_processed['Sex'])\n",
    "            print(f\"   - Sex: Encoded as {dict(zip(self.label_encoders['Sex'].classes_, self.label_encoders['Sex'].transform(self.label_encoders['Sex'].classes_)))}\")\n",
    "        else:\n",
    "            df_processed['Sex'] = self.label_encoders['Sex'].transform(df_processed['Sex'])\n",
    "        \n",
    "        # Prepare features and target\n",
    "        X = df_processed[self.feature_names]\n",
    "        \n",
    "        if is_training:\n",
    "            y = df_processed['Survived']\n",
    "            print(f\"\\nd) Feature Scaling:\")\n",
    "            print(f\"   Using StandardScaler for numerical features\")\n",
    "            \n",
    "            # Fit and transform features\n",
    "            self.scaler = StandardScaler()\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "            \n",
    "            print(f\"\\n   Data after preprocessing:\")\n",
    "            print(f\"   - Features shape: {X_scaled.shape}\")\n",
    "            print(f\"   - Target shape: {y.shape}\")\n",
    "            print(f\"   - Survival distribution:\\n{y.value_counts()}\\n\")\n",
    "            \n",
    "            return X_scaled, y\n",
    "        else:\n",
    "            # Transform only (using fitted scaler)\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "            return X_scaled\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train the Logistic Regression model.\n",
    "        \n",
    "        Args:\n",
    "            X_train: Training features\n",
    "            y_train: Training target\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 3: MODEL TRAINING\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(\"\\nAlgorithm Selected: Logistic Regression\")\n",
    "        print(\"Training the model...\")\n",
    "        \n",
    "        self.model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Training accuracy\n",
    "        train_accuracy = self.model.score(X_train, y_train)\n",
    "        print(f\"\\nModel Training Complete!\")\n",
    "        print(f\"Training Accuracy: {train_accuracy:.4f}\\n\")\n",
    "    \n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the trained model on test data.\n",
    "        \n",
    "        Args:\n",
    "            X_test: Test features\n",
    "            y_test: Test target\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 4: MODEL EVALUATION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        # Classification Report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(\"-\" * 60)\n",
    "        print(classification_report(y_test, y_pred, \n",
    "                                   target_names=['Did Not Survive', 'Survived']))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(cm)\n",
    "        print(f\"\\nTrue Negatives: {cm[0, 0]}\")\n",
    "        print(f\"False Positives: {cm[0, 1]}\")\n",
    "        print(f\"False Negatives: {cm[1, 0]}\")\n",
    "        print(f\"True Positives: {cm[1, 1]}\\n\")\n",
    "    \n",
    "    def save_model(self):\n",
    "        \"\"\"Save the trained model and scaler to disk using pickle.\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 5: SAVING THE MODEL\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Save model using pickle\n",
    "        with open(self.model_path, 'wb') as f:\n",
    "            pickle.dump(self.model, f)\n",
    "        print(f\"\\nModel saved to: {self.model_path}\")\n",
    "        \n",
    "        # Save scaler\n",
    "        scaler_path = self.model_path.replace('.pkl', '_scaler.pkl')\n",
    "        with open(scaler_path, 'wb') as f:\n",
    "            pickle.dump(self.scaler, f)\n",
    "        print(f\"Scaler saved to: {scaler_path}\")\n",
    "        \n",
    "        # Save label encoders\n",
    "        encoder_path = self.model_path.replace('.pkl', '_encoders.pkl')\n",
    "        with open(encoder_path, 'wb') as f:\n",
    "            pickle.dump(self.label_encoders, f)\n",
    "        print(f\"Label encoders saved to: {encoder_path}\\n\")\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the trained model and scaler from disk.\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"STEP 6: RELOADING MODEL FOR PREDICTION\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load model\n",
    "        with open(self.model_path, 'rb') as f:\n",
    "            self.model = pickle.load(f)\n",
    "        print(f\"\\nModel loaded from: {self.model_path}\")\n",
    "        \n",
    "        # Load scaler\n",
    "        scaler_path = self.model_path.replace('.pkl', '_scaler.pkl')\n",
    "        with open(scaler_path, 'rb') as f:\n",
    "            self.scaler = pickle.load(f)\n",
    "        print(f\"Scaler loaded from: {scaler_path}\")\n",
    "        \n",
    "        # Load label encoders\n",
    "        encoder_path = self.model_path.replace('.pkl', '_encoders.pkl')\n",
    "        with open(encoder_path, 'rb') as f:\n",
    "            self.label_encoders = pickle.load(f)\n",
    "        print(f\"Label encoders loaded from: {encoder_path}\\n\")\n",
    "    \n",
    "    def predict_survival(self, passenger_data):\n",
    "        \"\"\"\n",
    "        Predict survival for a single or multiple passengers.\n",
    "        \n",
    "        Args:\n",
    "            passenger_data: Dictionary or list of dictionaries with passenger features\n",
    "                           Keys should be: Pclass, Sex, Age, SibSp, Fare\n",
    "        \n",
    "        Returns:\n",
    "            Prediction (0 or 1) and probability\n",
    "        \"\"\"\n",
    "        # Handle single passenger\n",
    "        if isinstance(passenger_data, dict):\n",
    "            passenger_data = [passenger_data]\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df_pred = pd.DataFrame(passenger_data)\n",
    "        \n",
    "        # Encode Sex\n",
    "        df_pred['Sex'] = self.label_encoders['Sex'].transform(df_pred['Sex'])\n",
    "        \n",
    "        # Select features\n",
    "        X_pred = df_pred[self.feature_names]\n",
    "        \n",
    "        # Scale features\n",
    "        X_pred_scaled = self.scaler.transform(X_pred)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(X_pred_scaled)\n",
    "        probabilities = self.model.predict_proba(X_pred_scaled)\n",
    "        \n",
    "        return predictions, probabilities\n",
    "    \n",
    "    def run_full_pipeline(self, train_filepath):\n",
    "        \"\"\"\n",
    "        Run the complete pipeline: load, preprocess, train, evaluate, and save.\n",
    "        \n",
    "        Args:\n",
    "            train_filepath: Path to the training dataset\n",
    "        \"\"\"\n",
    "        # Load data\n",
    "        df = self.load_data(train_filepath)\n",
    "        \n",
    "        # Preprocess data\n",
    "        X, y = self.preprocess_data(df, is_training=True)\n",
    "        \n",
    "        # Split data into training and testing sets (80-20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"DATA SPLIT\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "        print(f\"Test set size: {X_test.shape[0]} samples\\n\")\n",
    "        \n",
    "        # Train model\n",
    "        self.train_model(X_train, y_train)\n",
    "        \n",
    "        # Evaluate model\n",
    "        self.evaluate_model(X_test, y_test)\n",
    "        \n",
    "        # Save model\n",
    "        self.save_model()\n",
    "\n",
    "print(\"TitanicSurvivalPredictor class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21cd397",
   "metadata": {},
   "source": [
    "## Step 3: Initialize and Run the Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac789642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: LOADING DATASET\n",
      "============================================================\n",
      "Dataset loaded successfully!\n",
      "Shape: (891, 12)\n",
      "Columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "\n",
      "============================================================\n",
      "STEP 2: DATA PREPROCESSING\n",
      "============================================================\n",
      "\n",
      "a) Feature Selection:\n",
      "   Selected features: ['Pclass', 'Sex', 'Age', 'SibSp', 'Fare']\n",
      "   Target variable: Survived\n",
      "\n",
      "   Missing values before handling:\n",
      "   - Pclass: 0\n",
      "   - Sex: 0\n",
      "   - Age: 177\n",
      "   - SibSp: 0\n",
      "   - Fare: 0\n",
      "\n",
      "b) Handling Missing Values:\n",
      "   - Age: Filled missing values with median (28.00)\n",
      "   - Fare: Filled missing values with median (14.45)\n",
      "\n",
      "c) Encoding Categorical Variables:\n",
      "   - Sex: Encoded as {'female': np.int64(0), 'male': np.int64(1)}\n",
      "\n",
      "d) Feature Scaling:\n",
      "   Using StandardScaler for numerical features\n",
      "\n",
      "   Data after preprocessing:\n",
      "   - Features shape: (891, 5)\n",
      "   - Target shape: (891,)\n",
      "   - Survival distribution:\n",
      "Survived\n",
      "0    549\n",
      "1    342\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "DATA SPLIT\n",
      "============================================================\n",
      "Training set size: 712 samples\n",
      "Test set size: 179 samples\n",
      "\n",
      "============================================================\n",
      "STEP 3: MODEL TRAINING\n",
      "============================================================\n",
      "\n",
      "Algorithm Selected: Logistic Regression\n",
      "Training the model...\n",
      "\n",
      "Model Training Complete!\n",
      "Training Accuracy: 0.7893\n",
      "\n",
      "============================================================\n",
      "STEP 4: MODEL EVALUATION\n",
      "============================================================\n",
      "\n",
      "Test Accuracy: 0.7989\n",
      "\n",
      "Classification Report:\n",
      "------------------------------------------------------------\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Did Not Survive       0.82      0.86      0.84       110\n",
      "       Survived       0.76      0.70      0.73        69\n",
      "\n",
      "       accuracy                           0.80       179\n",
      "      macro avg       0.79      0.78      0.78       179\n",
      "   weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[95 15]\n",
      " [21 48]]\n",
      "\n",
      "True Negatives: 95\n",
      "False Positives: 15\n",
      "False Negatives: 21\n",
      "True Positives: 48\n",
      "\n",
      "============================================================\n",
      "STEP 5: SAVING THE MODEL\n",
      "============================================================\n",
      "\n",
      "Model saved to: titanic_model.pkl\n",
      "Scaler saved to: titanic_model_scaler.pkl\n",
      "Label encoders saved to: titanic_model_encoders.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the predictor\n",
    "predictor = TitanicSurvivalPredictor(model_path='titanic_model.pkl')\n",
    "\n",
    "# Run the complete pipeline\n",
    "predictor.run_full_pipeline('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241059b",
   "metadata": {},
   "source": [
    "## Step 4: Demonstrate Model Reload and Prediction\n",
    "\n",
    "This step demonstrates that the saved model can be reloaded and used for prediction without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47d334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DEMONSTRATION: RELOADING AND PREDICTING\n",
      "============================================================\n",
      "============================================================\n",
      "STEP 6: RELOADING MODEL FOR PREDICTION\n",
      "============================================================\n",
      "\n",
      "Model loaded from: titanic_model.pkl\n",
      "Scaler loaded from: titanic_model_scaler.pkl\n",
      "Label encoders loaded from: titanic_model_encoders.pkl\n",
      "\n",
      "\n",
      "Testing model with sample passengers:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DEMONSTRATION: RELOADING AND PREDICTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a new predictor instance\n",
    "predictor_reload = TitanicSurvivalPredictor(model_path='titanic_model.pkl')\n",
    "\n",
    "# Load the saved model\n",
    "predictor_reload.load_model()\n",
    "\n",
    "print(\"\\nTesting model with sample passengers:\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d022c4",
   "metadata": {},
   "source": [
    "### Sample 1: Wealthy Female Passenger (High Chance of Survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7a22b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passenger 1: Wealthy female (1st class, 35 years old)\n",
      "  Prediction: SURVIVED\n",
      "  Probability of NOT surviving: 0.0973\n",
      "  Probability of SURVIVING: 0.9027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_1 = {\n",
    "    'Pclass': 1,\n",
    "    'Sex': 'female',\n",
    "    'Age': 35,\n",
    "    'SibSp': 1,\n",
    "    'Fare': 71.28\n",
    "}\n",
    "\n",
    "pred, prob = predictor_reload.predict_survival(sample_1)\n",
    "survival_label = \"SURVIVED\" if pred[0] == 1 else \"DID NOT SURVIVE\"\n",
    "\n",
    "print(\"Passenger 1: Wealthy female (1st class, 35 years old)\")\n",
    "print(f\"  Prediction: {survival_label}\")\n",
    "print(f\"  Probability of NOT surviving: {prob[0][0]:.4f}\")\n",
    "print(f\"  Probability of SURVIVING: {prob[0][1]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47247870",
   "metadata": {},
   "source": [
    "### Sample 2: Poor Male Passenger (Low Chance of Survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7736d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passenger 2: Poor male (3rd class, 25 years old)\n",
      "  Prediction: DID NOT SURVIVE\n",
      "  Probability of NOT surviving: 0.8908\n",
      "  Probability of SURVIVING: 0.1092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_2 = {\n",
    "    'Pclass': 3,\n",
    "    'Sex': 'male',\n",
    "    'Age': 25,\n",
    "    'SibSp': 0,\n",
    "    'Fare': 7.75\n",
    "}\n",
    "\n",
    "pred, prob = predictor_reload.predict_survival(sample_2)\n",
    "survival_label = \"SURVIVED\" if pred[0] == 1 else \"DID NOT SURVIVE\"\n",
    "\n",
    "print(\"Passenger 2: Poor male (3rd class, 25 years old)\")\n",
    "print(f\"  Prediction: {survival_label}\")\n",
    "print(f\"  Probability of NOT surviving: {prob[0][0]:.4f}\")\n",
    "print(f\"  Probability of SURVIVING: {prob[0][1]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278eacb",
   "metadata": {},
   "source": [
    "### Sample 3: Middle-Class Young Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bed6897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passenger 3: Middle-class male (2nd class, 18 years old)\n",
      "  Prediction: DID NOT SURVIVE\n",
      "  Probability of NOT surviving: 0.7865\n",
      "  Probability of SURVIVING: 0.2135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_3 = {\n",
    "    'Pclass': 2,\n",
    "    'Sex': 'male',\n",
    "    'Age': 18,\n",
    "    'SibSp': 2,\n",
    "    'Fare': 21.07\n",
    "}\n",
    "\n",
    "pred, prob = predictor_reload.predict_survival(sample_3)\n",
    "survival_label = \"SURVIVED\" if pred[0] == 1 else \"DID NOT SURVIVE\"\n",
    "\n",
    "print(\"Passenger 3: Middle-class male (2nd class, 18 years old)\")\n",
    "print(f\"  Prediction: {survival_label}\")\n",
    "print(f\"  Probability of NOT surviving: {prob[0][0]:.4f}\")\n",
    "print(f\"  Probability of SURVIVING: {prob[0][1]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc7bd1d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Accomplishments:\n",
    "\n",
    "✓ **Model was saved to disk using pickle** - Files saved:\n",
    "  - `titanic_model.pkl` - The trained Logistic Regression model\n",
    "  - `titanic_model_scaler.pkl` - The StandardScaler for feature normalization\n",
    "  - `titanic_model_encoders.pkl` - The LabelEncoders for categorical features\n",
    "\n",
    "✓ **Model was successfully reloaded without retraining**\n",
    "\n",
    "✓ **Model can make predictions on new data** with probability scores\n",
    "\n",
    "✓ **Feature Engineering** - Selected and preprocessed 5 optimal features\n",
    "\n",
    "✓ **Data Preprocessing** - Handled missing values, encoded categorical variables, and scaled features\n",
    "\n",
    "✓ **Model Evaluation** - Generated comprehensive classification reports and confusion matrices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
